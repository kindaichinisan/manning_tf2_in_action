{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering with BERT (HuggingFace)\n",
    "\n",
    "Deep learning has been revolutionized by transformer models. Transformer based models like BERT are heavily used in NLP to solve tasks due to the rich numerical representations of text they provide. Here we will be discussing how to use HuggingFace's transformers library to conveniently explore various transformer based NLP models. We will be training a question answering model on the famous SQUAD v1 dataset.\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch13-Transormers-with-TF2-and-Huggingface/13.2_Question_answering_with_BERT.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertConfig, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "    try:\n",
    "        transformers.trainer_utils.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: transformers module is not imported. Setting the seed for transformers failed.\")\n",
    "        \n",
    "# Fixing the random seed\n",
    "random_seed=4321\n",
    "fix_random_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "For this we will be using the [SQUAD v1 dataset](https://rajpurkar.github.io/SQuAD-explorer/). It is a question answering dataset. You are provided with a question, a context (e.g. a paragraph in which the answer to the question may exist) and finally the answer. Your goal is to, given the question and the context predict the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b49d159e6342aeb5356fbfd678ad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09be8f43c36d45bd82bea42ef0a103e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\thush\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed9555ca2364762bab04214da277194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Section 13.3\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the first 5 samples in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n",
       " {'text': ['a copper statue of Christ'], 'answer_start': [188]},\n",
       " {'text': ['the Main Building'], 'answer_start': [279]},\n",
       " {'text': ['a Marian place of prayer and reflection'], 'answer_start': [381]},\n",
       " {'text': ['a golden statue of the Virgin Mary'], 'answer_start': [92]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"answers\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting incorrect offsets of the provided answers\n",
    "\n",
    "The answers are provided by means of the, starting index (`answer_start`) and the answer it self (`text`). However, for some examples, the starting index is slightly off from the actual index. In the function belowe we correct that. Furthermore, we will add `answer_end`, which will denote the index of the position the answer ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data corrections\n",
      "\t87599/87599 examples had the correct answer indices\n",
      "\t0/87599 examples had the wrong answer indices\n",
      "\n",
      "Validation data correction\n",
      "\t10570/10570 examples had the correct answer indices\n",
      "\t0/10570 examples had the wrong answer indices\n"
     ]
    }
   ],
   "source": [
    "# Section 13.3\n",
    "\n",
    "# Code listing 13.5\n",
    "def correct_indices_add_end_idx(answers, contexts):\n",
    "    \"\"\" Correct the answer index of the samples (if wrong) \"\"\"\n",
    "    \n",
    "    # Track how many were correct and fixed\n",
    "    n_correct, n_fix = 0, 0\n",
    "    fixed_answers = []\n",
    "    for answer, context in zip(answers, contexts):\n",
    "\n",
    "        gold_text = answer['text'][0]\n",
    "        answer['text'] = gold_text\n",
    "        start_idx = answer['answer_start'][0]\n",
    "        answer['answer_start'] = start_idx\n",
    "        if start_idx <0 or len(gold_text.strip())==0:\n",
    "            print(answer)\n",
    "        end_idx = start_idx + len(gold_text)        \n",
    "        \n",
    "        # sometimes squad answers are off by a character or two â€“ fix this\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "            n_correct += 1\n",
    "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
    "            n_fix += 1\n",
    "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 2\n",
    "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "            n_fix +=1\n",
    "        \n",
    "        fixed_answers.append(answer)\n",
    "        \n",
    "    # Print how many samples were fixed\n",
    "    print(\"\\t{}/{} examples had the correct answer indices\".format(n_correct, len(answers)))\n",
    "    print(\"\\t{}/{} examples had the wrong answer indices\".format(n_fix, len(answers)))\n",
    "    return fixed_answers, contexts\n",
    "\n",
    "train_questions = dataset[\"train\"][\"question\"]\n",
    "print(\"Training data corrections\")\n",
    "train_answers, train_contexts = correct_indices_add_end_idx(\n",
    "    dataset[\"train\"][\"answers\"], dataset[\"train\"][\"context\"]\n",
    ")\n",
    "test_questions = dataset[\"validation\"][\"question\"]\n",
    "print(\"\\nValidation data correction\")\n",
    "test_answers, test_contexts = correct_indices_add_end_idx(\n",
    "    dataset[\"validation\"][\"answers\"], dataset[\"validation\"][\"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question answering with DistilBert\n",
    "\n",
    "Now we will start our way to train a question answering model. The pretrained model we'll be using is known as [DistilBert](https://arxiv.org/pdf/1910.01108.pdf). It is a variant of BERT trained using a knowledge distilliation mechanism (a type of transfer learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert some text to tokens with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[ 101, 2023, 2003, 1996, 6123,  102, 2023, 2003, 1996, 3160,  102]])>, 'attention_mask': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}\n",
      "['[CLS]', 'this', 'is', 'the', 'context', '[SEP]', 'this', 'is', 'the', 'question', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "context = \"This is the context\"\n",
    "question = \"This is the question\"\n",
    "\n",
    "token_ids = tokenizer(context, question, return_tensors='tf')\n",
    "print(token_ids)\n",
    "print(tokenizer.convert_ids_to_tokens(token_ids['input_ids'].numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the inputs to tokens\n",
    "\n",
    "In adition to converting inputs to tokens and adding special tokens, it will truncate and pad inputs to the maximum length of the sequences defined in the model config. For example, you can check model config with, `tokenizer.model_max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_encodings.shape: (87599, 512)\n",
      "test_encodings.shape: (10570, 512)\n"
     ]
    }
   ],
   "source": [
    "# Code listing 13.6\n",
    "\n",
    "# Encode train data\n",
    "# train_encodings -> transformers.tokenization_utils_base.BatchEncoding\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True, return_tensors='tf')\n",
    "print(\"train_encodings.shape: {}\".format(train_encodings[\"input_ids\"].shape))\n",
    "# Encode test data\n",
    "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True, return_tensors='tf')\n",
    "print(\"test_encodings.shape: {}\".format(test_encodings[\"input_ids\"].shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with truncated answers\n",
    "\n",
    "In the original dataset the `answer_start` and `answer_end` denote the *character*-level position of the answer. But in the model, since we deal in tokens we need the *token*-level position of the answer. For that, we will use the `char_to_token` function in the tokenizer. It will convert the character index to a token index.\n",
    "\n",
    "Because we are enforcing a maximum sequence length of 512, some answers will be inevitably truncated if they are present after the 512th token. Although this is rare, we still need to take care of this as it can result in numerical errors otherwise. Therefore, if the positions are `None` (i.e. couldn't find the answer), it is set to the maximum position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/87599 had answers truncated\n",
      "8/10570 had answers truncated\n"
     ]
    }
   ],
   "source": [
    "# Code listing 13.7\n",
    "def update_char_to_token_positions_inplace(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    n_updates = 0\n",
    "    # Go through all the answers\n",
    "    for i in range(len(answers)):        \n",
    "        \n",
    "        # Get the token position for both start end char positions\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "        \n",
    "        if start_positions[-1] is None or end_positions[-1] is None:\n",
    "            n_updates += 1\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        # In the guide, https://huggingface.co/transformers/custom_datasets.html#qa-squad\n",
    "        # they set it to model_max_length, but this will result in NaN losses as the last\n",
    "        # available label is model_max_length-1 (zero-indexed)\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length -1\n",
    "            \n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length -1\n",
    "            \n",
    "    print(\"{}/{} had answers truncated\".format(n_updates, len(answers)))\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "update_char_to_token_positions_inplace(train_encodings, train_answers)\n",
    "update_char_to_token_positions_inplace(test_encodings, test_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TensorFlow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train data\n",
      "\tDone\n",
      "Creating test data\n",
      "\tDone\n"
     ]
    }
   ],
   "source": [
    "# Section 13.3\n",
    "\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def data_gen(input_ids, attention_mask, start_positions, end_positions):\n",
    "    \"\"\" Generator for data \"\"\"\n",
    "    for inps, attn, start_pos, end_pos in zip(input_ids, attention_mask, start_positions, end_positions):\n",
    "        \n",
    "        yield (inps, attn), (start_pos, end_pos)\n",
    "        \n",
    "print(\"Creating train data\")\n",
    "\n",
    "# Define the generator as a callable (not the generator it self)\n",
    "train_data_gen = partial(data_gen,\n",
    "    input_ids=train_encodings['input_ids'], attention_mask=train_encodings['attention_mask'],\n",
    "    start_positions=train_encodings['start_positions'], end_positions=train_encodings['end_positions']\n",
    ")\n",
    "\n",
    "# Define the dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_data_gen, output_types=(('int32', 'int32'), ('int32', 'int32'))\n",
    ")\n",
    "# Shuffling the data\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "print('\\tDone')\n",
    "\n",
    "batch_size = 2 #8\n",
    "# Valid set is taken as the first 10000 samples in the shuffled set\n",
    "valid_dataset = train_dataset.take(10000)\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "# Rest is kept as the training data\n",
    "train_dataset = train_dataset.skip(10000)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "# Creating test data\n",
    "print(\"Creating test data\")\n",
    "\n",
    "# Define the generator as a callable\n",
    "test_data_gen = partial(data_gen,\n",
    "    input_ids=test_encodings['input_ids'], attention_mask=test_encodings['attention_mask'],\n",
    "    start_positions=test_encodings['start_positions'], end_positions=test_encodings['end_positions']\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    test_data_gen, output_types=(('int32', 'int32'), ('int32', 'int32'))\n",
    ")\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "print(\"\\tDone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "\n",
    "Here we define a DistilBert model (particularly a TF variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForQuestionAnswering: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig, TFDistilBertForQuestionAnswering\n",
    "\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", return_dict=False)\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "\n",
    "# Code listing 13.8\n",
    "def tf_wrap_model(model):\n",
    "    \"\"\" Wraps the huggingface's model with in the Keras Functional API \"\"\"\n",
    "    \n",
    "    # If this is not wrapped in a keras model by taking the correct tensors from\n",
    "    # TFQuestionAnsweringModelOutput produced, you will get the following error\n",
    "    # setting return_dict did not seem to work as it should\n",
    "    \n",
    "    # TypeError: The two structures don't have the same sequence type. \n",
    "    # Input structure has type <class 'tuple'>, while shallow structure has type \n",
    "    # <class 'transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput'>.\n",
    "    \n",
    "    # Define inputs\n",
    "    input_ids = tf.keras.layers.Input([None,], dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input([None,], dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    # Define the output (TFQuestionAnsweringModelOutput)\n",
    "    out = model([input_ids, attention_mask])\n",
    "    \n",
    "    # Get the correct attributes in the produced object to generate an output tuple\n",
    "    wrap_model = tf.keras.models.Model([input_ids, attention_mask], outputs=(out.start_logits, out.end_logits))\n",
    "    \n",
    "    return wrap_model\n",
    "\n",
    "\n",
    "# Define and compile the model\n",
    "\n",
    "# Keras will assign a separate loss for each output and add them together. So we'll just use the standard CE loss\n",
    "# instead of using the built-in model.compute_loss, which expects a dict of outputs and averages the two terms.\n",
    "# Note that this means the loss will be 2x of when using TFTrainer since we're adding instead of averaging them.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model_v2 = tf_wrap_model(model)\n",
    "model_v2.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3' defined at (most recent call last):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\thush\\AppData\\Local\\Temp\\ipykernel_18036\\3436384777.py\", line 7, in <cell line: 7>\n      model_v2.fit(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 1029, in call\n      distilbert_output = self.distilbert(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 401, in call\n      tfmr_output = self.transformer(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 313, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 317, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 265, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 205, in call\n      context = unshape(context)  # (bs, q_length, dim)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 183, in unshape\n      return tf.reshape(tf.transpose(x, perm=(0, 2, 1, 3)), (bs, -1, self.n_heads * dim_per_head))\nNode: 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3'\nDetected at node 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3' defined at (most recent call last):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\thush\\AppData\\Local\\Temp\\ipykernel_18036\\3436384777.py\", line 7, in <cell line: 7>\n      model_v2.fit(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 1029, in call\n      distilbert_output = self.distilbert(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 401, in call\n      tfmr_output = self.transformer(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 313, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 317, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 265, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 205, in call\n      context = unshape(context)  # (bs, q_length, dim)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 183, in unshape\n      return tf.reshape(tf.transpose(x, perm=(0, 2, 1, 3)), (bs, -1, self.n_heads * dim_per_head))\nNode: 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2,512,12,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[sparse_categorical_crossentropy_1/cond/then/_12/sparse_categorical_crossentropy_1/cond/cond/pivot_f/_186/_385]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2,512,12,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_16203]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds to complete the training\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(t2\u001b[38;5;241m-\u001b[39mt1))\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3' defined at (most recent call last):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\thush\\AppData\\Local\\Temp\\ipykernel_18036\\3436384777.py\", line 7, in <cell line: 7>\n      model_v2.fit(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 1029, in call\n      distilbert_output = self.distilbert(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 401, in call\n      tfmr_output = self.transformer(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 313, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 317, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 265, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 205, in call\n      context = unshape(context)  # (bs, q_length, dim)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 183, in unshape\n      return tf.reshape(tf.transpose(x, perm=(0, 2, 1, 3)), (bs, -1, self.n_heads * dim_per_head))\nNode: 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3'\nDetected at node 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3' defined at (most recent call last):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\thush\\AppData\\Local\\Temp\\ipykernel_18036\\3436384777.py\", line 7, in <cell line: 7>\n      model_v2.fit(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 1029, in call\n      distilbert_output = self.distilbert(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1012, in run_call_with_unpacked_inputs\n      self._using_dummy_loss = True\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 401, in call\n      tfmr_output = self.transformer(\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 313, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 317, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 265, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 205, in call\n      context = unshape(context)  # (bs, q_length, dim)\n    File \"C:\\Anaconda3\\envs\\manning.tf2.9\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 183, in unshape\n      return tf.reshape(tf.transpose(x, perm=(0, 2, 1, 3)), (bs, -1, self.n_heads * dim_per_head))\nNode: 'model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2,512,12,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[sparse_categorical_crossentropy_1/cond/then/_12/sparse_categorical_crossentropy_1/cond/cond/pivot_f/_186/_385]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2,512,12,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_for_question_answering/distilbert/transformer/layer_._5/attention/transpose_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_16203]"
     ]
    }
   ],
   "source": [
    "# Section 13.3\n",
    "\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "model_v2.fit(\n",
    "    train_dataset, \n",
    "    validation_data=valid_dataset,    \n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"It took {} seconds to complete the training\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_for_question_ans TFQuestionAnsweringM 66364418    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 66,364,418\n",
      "Trainable params: 66,364,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_v2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We cannot save `model_v2` as is, because it raises an error about not finding config for the transformer model layer. THerefore, we will save just the transformer model layer, so that we can call the `tf_wrap_model()` function anytime and get the wrapped model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizers/distilbert_qa/tokenizer_config.json',\n",
       " 'tokenizers/distilbert_qa/special_tokens_map.json',\n",
       " 'tokenizers/distilbert_qa/vocab.txt',\n",
       " 'tokenizers/distilbert_qa/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create folders\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "if not os.path.exists('tokenizers'):\n",
    "    os.makedirs('tokenizers')\n",
    "    \n",
    "# Save the modle\n",
    "model_v2.get_layer(\"tf_distil_bert_for_question_answering\").save_pretrained(os.path.join('models', 'distilbert_qa'))\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(os.path.join('tokenizers', 'distilbert_qa'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322/1322 [==============================] - 166s 126ms/step - loss: 2.4768 - tf_distil_bert_for_question_answering_loss: 1.2703 - tf_distil_bert_for_question_answering_1_loss: 1.2065 - tf_distil_bert_for_question_answering_sparse_categorical_accuracy: 0.6570 - tf_distil_bert_for_question_answering_1_sparse_categorical_accuracy: 0.6936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4768142700195312,\n",
       " 1.2703046798706055,\n",
       " 1.2065105438232422,\n",
       " 0.657048225402832,\n",
       " 0.6935666799545288]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask BERT a question ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "\t What was the theme of Super Bowl 50? \n",
      "\n",
      "Context\n",
      "\t Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. \n",
      "\n",
      "Answer (char indexed)\n",
      "\t {'answer_start': 487, 'text': '\"golden anniversary\"', 'answer_end': 507} \n",
      "\n",
      "================================================== \n",
      "\n",
      "98-99 token ids contain the answer\n",
      "Answer (predicted)\n",
      "golden anniversary\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Section 13.3\n",
    "\n",
    "# Code listing 13.9\n",
    "i = 5\n",
    "\n",
    "# Define sample question\n",
    "sample_q = test_questions[i]\n",
    "# Define sample context\n",
    "sample_c = test_contexts[i]\n",
    "# Define sample answer \n",
    "sample_a = test_answers[i]\n",
    "\n",
    "# Get the input in the format BERT accepts\n",
    "sample_input = (test_encodings[\"input_ids\"][i:i+1], test_encodings[\"attention_mask\"][i:i+1])\n",
    "\n",
    "def ask_bert(sample_input, tokenizer, model):\n",
    "    \"\"\" This function takes an input, a tokenizer, a model and returns the prediciton \"\"\"\n",
    "    out = model.predict(sample_input)\n",
    "    pred_ans_start = tf.argmax(out[0][0])\n",
    "    pred_ans_end = tf.argmax(out[1][0])\n",
    "    print(\"{}-{} token ids contain the answer\".format(pred_ans_start, pred_ans_end))\n",
    "    ans_tokens = sample_input[0][0][pred_ans_start:pred_ans_end+1]\n",
    "    \n",
    "    return \" \".join(tokenizer.convert_ids_to_tokens(ans_tokens))\n",
    "\n",
    "print(\"Question\")\n",
    "print(\"\\t\", sample_q, \"\\n\")\n",
    "print(\"Context\")\n",
    "print(\"\\t\", sample_c, \"\\n\")\n",
    "print(\"Answer (char indexed)\")\n",
    "print(\"\\t\", sample_a, \"\\n\")\n",
    "print('='*50,'\\n')\n",
    "\n",
    "sample_pred_ans = ask_bert(sample_input, tokenizer, model_v2)\n",
    "\n",
    "print(\"Answer (predicted)\")\n",
    "print(sample_pred_ans)\n",
    "print('='*50,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging the model for NaN losses\n",
    "\n",
    "This is a few things you can do to debug your model if you get nan losses. Here I demonstrate some checks you can do on the model to find out errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForQuestionAnswering: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_59', 'qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label out of range >\n",
      "tf.Tensor(\n",
      "[[-0.1142147   0.09263498  0.13831475 ... -0.03982427 -0.06281633\n",
      "   0.02767614]\n",
      " [-0.05274756  0.05098321  0.2543083  ...  0.09835686  0.00608967\n",
      "  -0.0975308 ]\n",
      " [-0.10279585  0.11235896 -0.10606081 ... -0.01665854 -0.04991871\n",
      "  -0.07675146]\n",
      " ...\n",
      " [-0.17991495  0.32203868 -0.24517833 ... -0.1336475  -0.20179018\n",
      "  -0.18071416]\n",
      " [-0.24569106 -0.03969484 -0.19127595 ... -0.15528637 -0.09771455\n",
      "  -0.11388561]\n",
      " [-0.05893413  0.07534678  0.23509616 ... -0.0332404   0.02945572\n",
      "  -0.07513344]], shape=(8, 512), dtype=float32)\n",
      "(<tf.Tensor: shape=(8, 512), dtype=int32, numpy=\n",
      "array([[  101, 13525,  1005, ...,     0,     0,     0],\n",
      "       [  101,  2043,  3424, ...,     0,     0,     0],\n",
      "       [  101,  2012,  1996, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  7387, 16846, ...,     0,     0,     0],\n",
      "       [  101,  6178,  6305, ...,     0,     0,     0],\n",
      "       [  101,  2070,  4401, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(8, 512), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>)\n",
      "tf.Tensor([  9 221  76 512  87   1  55  96], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig, TFDistilBertForQuestionAnswering\n",
    "\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", return_dict=True)\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "\n",
    "for i,(x,y) in enumerate(train_dataset):\n",
    "    print(i, end='\\r')\n",
    "    print(\"Found error in the batch {}\".format(i))\n",
    "    \n",
    "    # Get the model output\n",
    "    out = model(x)\n",
    "    \n",
    "    # Check any index in the labels is greater than the max length\n",
    "    if tf.reduce_sum(tf.cast(y[0]>511, 'int32'))>0:\n",
    "        print('start label out of range >')\n",
    "        print(out.start_logits)\n",
    "        print(x)\n",
    "        print(y[0])\n",
    "        break\n",
    "    # Check if any index in the labels is smaller than zero\n",
    "    if tf.reduce_sum(tf.cast(y[0]<0, 'int32'))>0:\n",
    "        print('start label out of range <')\n",
    "        print(out.start_logits)\n",
    "        print(x)\n",
    "        print(y[0])\n",
    "        break\n",
    "    # Check any index in the labels is greater than the max length\n",
    "    if tf.reduce_sum(tf.cast(y[1]>511, 'int32'))>0:\n",
    "        print('end label out of range >')\n",
    "        print(out.start_logits)\n",
    "        print(x)\n",
    "        print(y[1])\n",
    "        break\n",
    "    # Check if any index in the labels is smaller than zero\n",
    "    if tf.reduce_sum(tf.cast(y[1]<0, 'int32'))>0:\n",
    "        print('end label out of range <')\n",
    "        print(out.start_logits)\n",
    "        print(x)\n",
    "        print(y[1])\n",
    "        break\n",
    "    # Check if any loss is nan    \n",
    "    if tf.math.is_nan(tf.reduce_sum(out.start_logits)):\n",
    "        print('start_logits were nan')\n",
    "        print(out.start_logits)\n",
    "        print(x)\n",
    "        print(y)\n",
    "        break\n",
    "    # Check if any loss is nan\n",
    "    if tf.math.is_nan(tf.reduce_sum(out.end_logits)):\n",
    "        print('end_logits were nan')\n",
    "        print(out.end_logits)\n",
    "        print(x)\n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
